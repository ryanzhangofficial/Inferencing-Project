{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "559022b2-d0df-48bc-841c-7f6985b0c6e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.44.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (2.4.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.9.1)\n",
      "Requirement already satisfied: rouge_score in /usr/local/lib/python3.8/dist-packages (0.1.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\" in /usr/local/lib/python3.8/dist-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (7.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge_score) (1.14.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (12.6.68)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch nltk rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3eb85c2-3d8d-4591-8c4c-55fe2b8fa2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "# from framework.utilities.models import inference    \n",
    "from framework.utilities.metrics import calculate_bleu, calculate_rouge\n",
    "import fastText\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "import json\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1d3fd4-70ab-4ab7-8655-026494ee67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_monitoring.monitor import HWMonitor\n",
    "import threading\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c35647b-894f-4627-b57d-330eba72e97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ccdead-eb3c-48fb-ad8e-3a7e2afc78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_outputs[\"gsm8k\"] = [{\"input_text\": None, \"7b\": None, \"tiny\": None, \"13b\": None} for _ in range(3000)]\n",
    "# len(combined_outputs[\"gsm8k\"])\n",
    "\n",
    "# with open('data/input_output_train', 'wb') as f:\n",
    "#     pickle.dump(combined_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d038580-deb8-4ade-a503-f54e18e9c802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wmt14</th>\n",
       "      <th>cnn_dailymail</th>\n",
       "      <th>gsm8k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'input_text': 'Gutach: Noch mehr Sicherheit f...</td>\n",
       "      <td>{'input_text': '(CNN)The Palestinian Authority...</td>\n",
       "      <td>{'input_text': None, '7b': None, 'tiny': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'input_text': 'Sie stehen keine 100 Meter von...</td>\n",
       "      <td>{'input_text': '(CNN)Never mind cats having ni...</td>\n",
       "      <td>{'input_text': None, '7b': None, 'tiny': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'input_text': 'Zwei Anlagen so nah beieinande...</td>\n",
       "      <td>{'input_text': '(CNN)If you've been following ...</td>\n",
       "      <td>{'input_text': None, '7b': None, 'tiny': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'input_text': 'Diese Frage hat Gutachs Bürger...</td>\n",
       "      <td>{'input_text': '(CNN)Five Americans who were m...</td>\n",
       "      <td>{'input_text': None, '7b': None, 'tiny': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'input_text': '\"Die Rathausampel ist damals i...</td>\n",
       "      <td>{'input_text': '(CNN)A Duke student has admitt...</td>\n",
       "      <td>{'input_text': None, '7b': None, 'tiny': None,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               wmt14  \\\n",
       "0  {'input_text': 'Gutach: Noch mehr Sicherheit f...   \n",
       "1  {'input_text': 'Sie stehen keine 100 Meter von...   \n",
       "2  {'input_text': 'Zwei Anlagen so nah beieinande...   \n",
       "3  {'input_text': 'Diese Frage hat Gutachs Bürger...   \n",
       "4  {'input_text': '\"Die Rathausampel ist damals i...   \n",
       "\n",
       "                                       cnn_dailymail  \\\n",
       "0  {'input_text': '(CNN)The Palestinian Authority...   \n",
       "1  {'input_text': '(CNN)Never mind cats having ni...   \n",
       "2  {'input_text': '(CNN)If you've been following ...   \n",
       "3  {'input_text': '(CNN)Five Americans who were m...   \n",
       "4  {'input_text': '(CNN)A Duke student has admitt...   \n",
       "\n",
       "                                               gsm8k  \n",
       "0  {'input_text': None, '7b': None, 'tiny': None,...  \n",
       "1  {'input_text': None, '7b': None, 'tiny': None,...  \n",
       "2  {'input_text': None, '7b': None, 'tiny': None,...  \n",
       "3  {'input_text': None, '7b': None, 'tiny': None,...  \n",
       "4  {'input_text': None, '7b': None, 'tiny': None,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('data/input_output_train', 'rb') as file:\n",
    "    combined_outputs = pickle.load(file)\n",
    "\n",
    "df_combined_outputs = pd.DataFrame(combined_outputs)\n",
    "df_combined_outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147f54d5-e9f2-4812-b50b-d7045e7c14f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_outputs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22851f3c-bc40-4374-9a2f-04633425d8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': \"(CNN)Five Americans who were monitored for three weeks at an Omaha, Nebraska, hospital after being exposed to Ebola in West Africa have been released, a Nebraska Medicine spokesman said in an email Wednesday. One of the five had a heart-related issue on Saturday and has been discharged but hasn't left the area, Taylor Wilson wrote. The others have already gone home. They were exposed to Ebola in Sierra Leone in March, but none developed the deadly virus. They are clinicians for Partners in Health, a Boston-based aid group. They all had contact with a colleague who was diagnosed with the disease and is being treated at the National Institutes of Health in Bethesda, Maryland. As of Monday, that health care worker is in fair condition. The Centers for Disease Control and Prevention in Atlanta has said the last of 17 patients who were being monitored are expected to be released by Thursday. More than 10,000 people have died in a West African epidemic of Ebola that dates to December 2013, according to the World Health Organization. Almost all the deaths have been in Guinea, Liberia and Sierra Leone. Ebola is spread by direct contact with the bodily fluids of an infected person.\",\n",
       " '7b': 'Five Americans who were exposed to Ebola in West Africa have been released from a Nebraska hospital after being monitored for three weeks.',\n",
       " '13b': 'In under 50 words, the text can be summarized as follows:\\n\\nFive Americans who were monitored for Ebola exposure in Nebraska after working in Sierra Leone have been released from the hospital, with one remaining in the area for further monitoring due to a heart-related issue.',\n",
       " 'tiny': 'Five Americans who were monitored for three weeks at an Omaha, Nebraska, hospital after being exposed to Ebola in West Africa have been released, a Nebraska Medicine spokesman said in an email.',\n",
       " 'label': '17 Americans were exposed to the Ebola virus while in Sierra Leone in March .\\nAnother person was diagnosed with the disease and taken to hospital in Maryland .\\nNational Institutes of Health says the patient is in fair condition after weeks of treatment .'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_outputs[\"cnn_dailymail\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d94dfcd-5386-4429-ae96-850f21d473ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm(T, c):\n",
    "    l_predictor, s_predictor = None, None\n",
    "    results = []\n",
    "    \n",
    "    for t in range(1, T+1):\n",
    "        print(f\"Index: {t}\")\n",
    "        t_i = df_combined_outputs[\"wmt14\"][t][\"input_text\"]\n",
    "        t_e = df_combined_outputs[\"wmt14\"][t][\"label\"]\n",
    "\n",
    "        p_t = min(1, c/math.sqrt(t))\n",
    "        X_t = Bernoulli(p_t)\n",
    "\n",
    "        l_loss, s_loss = None, None\n",
    "        if X_t == 1:\n",
    "            t_c = getResults(t, t_i, t_e)\n",
    "            l_predictor, s_predictor, l_loss, s_loss = sgdStep(t_c)\n",
    "            l_predictor, s_predictor = checkpoint(l_predictor, s_predictor, t, p_t)\n",
    "            \n",
    "        output, t_acc = queryBest(t, t_i, t_e, l_predictor, s_predictor)\n",
    "        log(results, t, t_i, output, t_acc, l_loss, s_loss)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f71fb4f-e6c0-495f-bca0-4eaa1520d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(results, t, t_i, output, t_acc, l_loss, s_loss):\n",
    "    results.append({\n",
    "        'iteration': t,\n",
    "        'input': t_i,\n",
    "        'best_output': output,\n",
    "        'chosen_model_accuracy': t_acc,\n",
    "        'l_loss': l_loss,\n",
    "        's_loss': s_loss\n",
    "    })\n",
    "    log_data = {\n",
    "        'iteration': t,\n",
    "        'chosen_model_accuracy': t_acc\n",
    "    }\n",
    "        \n",
    "    if l_loss is not None: log_data['l_loss'] = l_loss\n",
    "    if s_loss is not None: log_data['s_loss'] = s_loss\n",
    "        \n",
    "    wandb.log(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e3f4257-4e9b-49ba-ad82-312b64d73ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bernoulli(p_t):\n",
    "    return random.random() < p_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff8f84c0-4552-4f62-bf95-19cddaed2bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryBest(t, t_i, t_e, l_predictor, s_predictor):\n",
    "    l_acc, s_acc = predict(t_i, l_predictor, s_predictor)\n",
    "    if l_acc > s_acc: # use larger model, e.g. 7b llama\n",
    "        output = df_combined_outputs[\"wmt14\"][t][\"13b\"]\n",
    "    else: # use smaller model for all other cases, e.g. 3b llama\n",
    "        output =  df_combined_outputs[\"wmt14\"][t][\"tiny\"]\n",
    "\n",
    "    return output, calculate_bleu(output, t_e)\n",
    "    # return output, calculate_rouge(output, t_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "199d6079-a233-4862-8e7f-918c12cb4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_loss(predicted_accuracy, true_accuracy):\n",
    "    predicted_tensor = torch.tensor([predicted_accuracy], dtype=torch.float32)\n",
    "    true_tensor = torch.tensor([true_accuracy], dtype=torch.float32)\n",
    "\n",
    "    loss = F.mse_loss(predicted_tensor, true_tensor)\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df16dc77-e1db-4a51-a8bc-c1f76e85c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgdStep(t_c):\n",
    "    with open(\"fasttext_large.txt\", \"w\") as f:\n",
    "        f.write(f\"__label__{t_c['large_model_accuracy']} {t_c['input_text']}\\n\")\n",
    "    with open(\"fasttext_small.txt\", \"w\") as f:\n",
    "        f.write(f\"__label__{t_c['small_model_accuracy']} {t_c['input_text']}\\n\")\n",
    "\n",
    "    if os.path.exists(\"large_predictor.bin\"):\n",
    "        large_model_predictor = fastText.train_supervised(input=\"fasttext_large.txt\", epoch=1, lr=1.0, wordNgrams=2, inputModel=\"large_predictor.bin\")\n",
    "    else:\n",
    "        large_model_predictor = fastText.train_supervised(input=\"fasttext_large.txt\", epoch=1, lr=1.0, wordNgrams=2)\n",
    "\n",
    "    if os.path.exists(\"small_predictor.bin\"):\n",
    "        small_model_predictor = fastText.train_supervised(input=\"fasttext_small.txt\", epoch=1, lr=1.0, wordNgrams=2, inputModel=\"small_predictor.bin\")\n",
    "    else:\n",
    "        small_model_predictor = fastText.train_supervised(input=\"fasttext_small.txt\", epoch=1, lr=1.0, wordNgrams=2)\n",
    "\n",
    "    predicted_large_label = large_model_predictor.predict(t_c['input_text'])[0][0].replace(\"__label__\", \"\")\n",
    "    predicted_small_label = small_model_predictor.predict(t_c['input_text'])[0][0].replace(\"__label__\", \"\")\n",
    "\n",
    "    large_model_loss = compute_mse_loss(float(predicted_large_label), t_c['large_model_accuracy'])\n",
    "    small_model_loss = compute_mse_loss(float(predicted_small_label), t_c['small_model_accuracy'])\n",
    "\n",
    "    return large_model_predictor, small_model_predictor, large_model_loss, small_model_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55a0e73e-7a06-4071-9175-adbd53710be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(text, l_predictor, s_predictor):\n",
    "    l_predicted_label = l_predictor.predict(text)[0][0]\n",
    "    l_predicted_accuracy = int(round(float(l_predicted_label.replace('__label__', ''))))\n",
    "\n",
    "    s_predicted_label = s_predictor.predict(text)[0][0]\n",
    "    s_predicted_accuracy = int(round(float(s_predicted_label.replace('__label__', ''))))\n",
    "\n",
    "    return l_predicted_accuracy, s_predicted_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74d56eb4-a502-4583-961d-7b7c39eccd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(t, t_i, t_e):\n",
    "    s_output = df_combined_outputs[\"wmt14\"][t][\"tiny\"]\n",
    "    l_output = df_combined_outputs[\"wmt14\"][t][\"13b\"]\n",
    "    \n",
    "    # WMT14\n",
    "    s_acc = calculate_bleu(s_output, t_e)\n",
    "    l_acc = calculate_bleu(l_output, t_e)\n",
    "\n",
    "    # CNN Dailymail\n",
    "    # s_acc = calculate_rouge(s_output, t_e)['rouge1']\n",
    "    # l_acc = calculate_rouge(l_output, t_e)['rouge1']\n",
    "\n",
    "    return {\n",
    "        'input_text': t_i,\n",
    "        'large_model_accuracy': l_acc,\n",
    "        'small_model_accuracy': s_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a657f810-6521-4073-ab4d-bb1e7dee9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(l_predictor, s_predictor, t, p_t):\n",
    "    if p_t > 0.5:\n",
    "        if t % int(math.sqrt(t)) == 0:\n",
    "            print(\"Checkpoint\")\n",
    "            l_predictor, s_predictor = save_models(l_predictor, s_predictor)\n",
    "    else:\n",
    "        if t % max(1, int(1 / math.sqrt(t))) == 0:\n",
    "            print(\"Checkpoint\")\n",
    "            l_predictor, s_predictor = save_models(l_predictor, s_predictor)\n",
    "\n",
    "    return l_predictor, s_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "534194e3-df63-47f4-8aac-382813becd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(l_predictor, s_predictor):\n",
    "    if l_predictor:\n",
    "        l_predictor.save_model(\"large_predictor.bin\")\n",
    "    if s_predictor:\n",
    "        s_predictor.save_model(\"small_predictor.bin\")\n",
    "\n",
    "    return l_predictor, s_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c404d0a7-f482-44d8-ac62-3d34c5b59f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_record(samples, c):\n",
    "    wandb.init(project=\"classifier\")\n",
    "    stop_event = threading.Event()\n",
    "    hw_monitor = HWMonitor(monitoring_freq=1.0, stop_event=threading.Event())\n",
    "    hw_monitor.start()\n",
    "    \n",
    "    results = algorithm(samples, c)\n",
    "\n",
    "    stop_event.set() \n",
    "    hw_monitor.join()\n",
    "    wandb.finish()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31070f68-2a56-42c1-8e44-59c310bf42c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mryanzhangofficial\u001b[0m (\u001b[33mryzhangofficial\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/srv.nas/Inferencing-Project/wandb/run-20240920_064737-tpdd38ay</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ryzhangofficial/classifier/runs/tpdd38ay' target=\"_blank\">royal-music-63</a></strong> to <a href='https://wandb.ai/ryzhangofficial/classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ryzhangofficial/classifier' target=\"_blank\">https://wandb.ai/ryzhangofficial/classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ryzhangofficial/classifier/runs/tpdd38ay' target=\"_blank\">https://wandb.ai/ryzhangofficial/classifier/runs/tpdd38ay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: nvidia-smi: not found\n",
      "Read 0M words\n",
      "Number of words:  27\n",
      "Number of labels: 1\n",
      "/bin/sh: 1: nvidia-smi: not found\n",
      "/bin/sh: 1: nvidia-smi: not found\n",
      "start training...\n",
      "Progress: 100.0% words/sec/thread:   36436 lr:  0.000000 loss:  0.000000 ETA:   0h 0m0m\n",
      "Read 0M words\n",
      "Number of words:  27\n",
      "Number of labels: 1\n",
      "/bin/sh: 1: nvidia-smi: not found\n",
      "/bin/sh: 1: nvidia-smi: not found\n",
      "/bin/sh: 1: nvidia-smi: not found\n",
      "start training...\n",
      "Progress: 100.0% words/sec/thread:   44142 lr:  0.000000 loss:  0.000000 ETA:   0h 0m0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint\n",
      "Index: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: nvidia-smi: not found\n",
      "Read 0M words\n",
      "Number of words:  9\n",
      "Number of labels: 1\n",
      "/bin/sh: 1: nvidia-smi: not found\n",
      "/bin/sh: 1: nvidia-smi: not found\n",
      "start training...\n",
      "Progress: 100.0% words/sec/thread:   17762 lr:  0.000000 loss:  0.000000 ETA:   0h 0m0m\n",
      "Read 0M words\n",
      "Number of words:  9\n",
      "Number of labels: 1\n",
      "/bin/sh: 1: nvidia-smi: not found\n",
      "/bin/sh: 1: nvidia-smi: not found"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint\n",
      "Index: 3\n",
      "Checkpoint\n",
      "Index: 4\n",
      "Checkpoint\n",
      "Index: 5\n",
      "Index: 6\n",
      "Checkpoint\n",
      "Index: 7\n",
      "Index: 8\n",
      "Checkpoint\n",
      "Index: 9\n",
      "Checkpoint\n",
      "Index: 10\n",
      "Index: 11\n",
      "Index: 12\n",
      "Checkpoint\n",
      "Index: 13\n",
      "Index: 14\n",
      "Index: 15\n",
      "Checkpoint\n",
      "Index: 16\n",
      "Checkpoint\n",
      "Index: 31\n",
      "Index: 32\n",
      "Index: 33\n",
      "Index: 34\n",
      "Index: 35\n",
      "Checkpoint\n",
      "Index: 36\n",
      "Index: 37\n",
      "Index: 38\n",
      "Index: 39\n",
      "Index: 40\n",
      "Index: 41\n",
      "Index: 42\n",
      "Checkpoint\n",
      "Index: 43\n",
      "Index: 44\n",
      "Index: 45\n",
      "Index: 46\n",
      "Index: 47\n",
      "Index: 48\n",
      "Checkpoint\n",
      "Index: 49\n",
      "Checkpoint\n",
      "Index: 50\n",
      "Index: 51\n",
      "Index: 52\n",
      "Index: 53\n",
      "Index: 54\n",
      "Index: 55\n",
      "Index: 56\n",
      "Checkpoint\n",
      "Index: 57\n",
      "Index: 58\n",
      "Index: 59\n",
      "Index: 60\n",
      "Index: 61\n",
      "Index: 62\n",
      "Index: 63\n",
      "Checkpoint\n",
      "Index: 64\n",
      "Index: 65\n",
      "Index: 66\n",
      "Index: 67\n",
      "Index: 68\n",
      "Index: 69\n",
      "Index: 70\n",
      "Index: 71\n",
      "Index: 72\n",
      "Index: 73\n",
      "Index: 74\n",
      "Index: 75\n",
      "Index: 76\n",
      "Index: 77\n",
      "Index: 78\n",
      "Index: 79\n",
      "Index: 80\n",
      "Checkpoint\n",
      "Index: 81\n",
      "Checkpoint\n",
      "Index: 82\n",
      "Index: 83\n",
      "Index: 84\n",
      "Index: 85\n",
      "Index: 86\n",
      "Index: 87\n",
      "Index: 88\n",
      "Index: 89\n",
      "Index: 90\n",
      "Checkpoint\n",
      "Index: 91\n",
      "Index: 92\n",
      "Index: 93\n",
      "Index: 94\n",
      "Index: 95\n",
      "Index: 96\n",
      "Index: 97\n",
      "Index: 98\n",
      "Index: 99\n",
      "Index: 100\n",
      "Index: 101\n",
      "Checkpoint\n",
      "Index: 102\n",
      "Index: 103\n",
      "Index: 104\n",
      "Checkpoint\n",
      "Index: 105\n",
      "Checkpoint\n",
      "Index: 106\n",
      "Checkpoint\n",
      "Index: 107\n",
      "Index: 108\n",
      "Checkpoint\n",
      "Index: 109\n",
      "Index: 110\n",
      "Index: 111\n",
      "Checkpoint\n",
      "Index: 112\n",
      "Index: 113\n",
      "Index: 114\n",
      "Checkpoint\n",
      "Index: 115\n",
      "Index: 116\n",
      "Index: 117\n",
      "Index: 118\n",
      "Index: 119\n",
      "Index: 120\n",
      "Index: 121\n",
      "Checkpoint\n",
      "Index: 122\n",
      "Index: 123\n",
      "Index: 124\n",
      "Index: 125\n",
      "Index: 126\n",
      "Checkpoint\n",
      "Index: 127\n",
      "Index: 128\n",
      "Checkpoint\n",
      "Index: 129\n",
      "Index: 130\n",
      "Checkpoint\n",
      "Index: 131\n",
      "Checkpoint\n",
      "Index: 132\n",
      "Index: 133\n",
      "Checkpoint\n",
      "Index: 134\n",
      "Checkpoint\n",
      "Index: 135\n",
      "Checkpoint\n",
      "Index: 136\n",
      "Index: 137\n",
      "Index: 138\n",
      "Index: 139\n",
      "Checkpoint\n",
      "Index: 140\n",
      "Index: 141\n",
      "Checkpoint\n",
      "Index: 142\n",
      "Index: 143\n",
      "Index: 144\n",
      "Index: 145\n",
      "Index: 146\n",
      "Index: 147\n",
      "Checkpoint\n",
      "Index: 148\n",
      "Checkpoint\n",
      "Index: 149\n",
      "Checkpoint\n",
      "Index: 150\n",
      "Checkpoint\n",
      "Index: 151\n",
      "Index: 152\n",
      "Index: 153\n",
      "Index: 154\n",
      "Index: 155\n",
      "Checkpoint\n",
      "Index: 156\n",
      "Checkpoint\n",
      "Index: 157\n",
      "Index: 158\n",
      "Checkpoint\n",
      "Index: 159\n",
      "Index: 160\n",
      "Index: 161\n",
      "Index: 162\n",
      "Index: 163\n",
      "Index: 164\n",
      "Index: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    }
   ],
   "source": [
    "results = run_and_record(2999, 5)\n",
    "\n",
    "with open('experiments/fasttext/wmt14_results_5.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbbe3a-4cff-40b5-a463-c77a804b60bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_and_record(2999, 3)\n",
    "\n",
    "with open('experiments/fasttext/wmt14_results_3.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6eea6-7ffa-4c6c-90e3-c570a4716e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_and_record(2999, 1)\n",
    "\n",
    "with open('experiments/fasttext/wmt14_results_1.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f803c9-0796-41a2-a0f5-ea4a24906668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/wmt14_results.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for result in data[:10]:\n",
    "    print(result['chosen_model_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "200e54a1-ff42-40b0-acfb-36fdfbcc405a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18766023212954513"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "num_results = len(data)\n",
    "\n",
    "for result in data:\n",
    "    total += result['chosen_model_accuracy']\n",
    "\n",
    "total / num_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "885488a4-662f-49fb-9aa9-d4bec5f66cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/cnndailymail_results.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3296c62-d69f-4531-9c20-24935ba4b1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1: 0.2937870737089562\n",
      "Average ROUGE-2: 0.10789698165405123\n",
      "Average ROUGE-L: 0.19841589354653624\n"
     ]
    }
   ],
   "source": [
    "rouge1_total = 0\n",
    "rouge2_total = 0\n",
    "rougeL_total = 0\n",
    "\n",
    "num_results = len(data)\n",
    "\n",
    "for result in data:\n",
    "    rouge1_total += result['chosen_model_accuracy']['rouge1']\n",
    "    rouge2_total += result['chosen_model_accuracy']['rouge2']\n",
    "    rougeL_total += result['chosen_model_accuracy']['rougeL']\n",
    "\n",
    "rouge1_avg = rouge1_total / num_results\n",
    "rouge2_avg = rouge2_total / num_results\n",
    "rougeL_avg = rougeL_total / num_results\n",
    "\n",
    "print(f\"Average ROUGE-1: {rouge1_avg}\")\n",
    "print(f\"Average ROUGE-2: {rouge2_avg}\")\n",
    "print(f\"Average ROUGE-L: {rougeL_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24211535-1fae-4a68-b78b-1d84e6ceaa21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
