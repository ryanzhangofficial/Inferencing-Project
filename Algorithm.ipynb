{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559022b2-d0df-48bc-841c-7f6985b0c6e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch nltk rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb85c2-3d8d-4591-8c4c-55fe2b8fa2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "# from framework.utilities.models import inference    \n",
    "from framework.utilities.metrics import calculate_bleu, calculate_rouge\n",
    "import fastText\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "import json\n",
    "# import wandb\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from collections import deque\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d3fd4-70ab-4ab7-8655-026494ee67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_monitoring.monitor import HWMonitor\n",
    "import threading\n",
    "# import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35647b-894f-4627-b57d-330eba72e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ccdead-eb3c-48fb-ad8e-3a7e2afc78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_outputs[\"gsm8k\"] = [{\"input_text\": None, \"7b\": None, \"tiny\": None, \"13b\": None} for _ in range(3000)]\n",
    "# len(combined_outputs[\"gsm8k\"])\n",
    "\n",
    "# with open('data/input_output_train', 'wb') as f:\n",
    "#     pickle.dump(combined_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d038580-deb8-4ade-a503-f54e18e9c802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('data/input_output_train', 'rb') as file:\n",
    "    combined_outputs = pickle.load(file)\n",
    "\n",
    "df_combined_outputs = pd.DataFrame(combined_outputs)\n",
    "df_combined_outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f54d5-e9f2-4812-b50b-d7045e7c14f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_combined_outputs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22851f3c-bc40-4374-9a2f-04633425d8b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_combined_outputs[\"cnn_dailymail\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d94dfcd-5386-4429-ae96-850f21d473ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm(T, V, h_tilde, c):\n",
    "    l_predictor, s_predictor = None, None\n",
    "    Q = 0.0 \n",
    "    results = []\n",
    "\n",
    "    # l_loss_window = []\n",
    "    # s_loss_window = []\n",
    "    acc_all = []\n",
    "    energy_all = []\n",
    "\n",
    "    for t in range(1, T+1):\n",
    "        print(f\"Index: {t}\")\n",
    "        t_i = df_combined_outputs[\"wmt14\"][t][\"input_text\"]\n",
    "        t_e = df_combined_outputs[\"wmt14\"][t][\"label\"]\n",
    "\n",
    "        p_t = min(1, c / math.sqrt(t))\n",
    "        X_t = Bernoulli(p_t)\n",
    "\n",
    "        # l_loss, s_loss = None, None\n",
    "\n",
    "        g_large = 2.0\n",
    "        g_small = 1.0  \n",
    "\n",
    "        # if X_t == 1:\n",
    "        #     t_c = getResults(t, t_i, t_e)\n",
    "        #     l_actual_acc = t_c['large_model_accuracy']\n",
    "        #     s_actual_acc = t_c['small_model_accuracy']\n",
    "\n",
    "        #     l_predictor, s_predictor, l_loss, s_loss = sgdStep(l_predictor, s_predictor, t_c)\n",
    "        #     l_predictor, s_predictor = checkpoint(l_predictor, s_predictor, t, p_t)\n",
    "\n",
    "        #     cost_large = V * g_large + Q * (h_tilde - l_actual_acc)\n",
    "        #     cost_small = V * g_small + Q * (h_tilde - s_actual_acc)\n",
    "        # else:\n",
    "        # l_predicted_acc, s_predicted_acc = predict(t_i, l_predictor, s_predictor)\n",
    "\n",
    "        t_c = getResults(t, t_i, t_e)\n",
    "        l_actual_acc = t_c['large_model_accuracy']\n",
    "        s_actual_acc = t_c['small_model_accuracy']\n",
    "        cost_large = V * g_large + Q * (h_tilde - l_actual_acc)\n",
    "        cost_small = V * g_small + Q * (h_tilde - s_actual_acc)\n",
    "\n",
    "        print('Q=', Q)\n",
    "        if cost_large < cost_small:\n",
    "            x_t = 'large'\n",
    "            selected_acc = l_actual_acc # if X_t == 1 else l_predicted_acc\n",
    "            selected_energy = g_large\n",
    "            print('selected large')\n",
    "        else:\n",
    "            x_t = 'small'\n",
    "            selected_acc = s_actual_acc # if X_t == 1 else s_predicted_acc\n",
    "            selected_energy = g_small\n",
    "            print('selected small')\n",
    "\n",
    "        output, t_acc = querySelectedModel(t, t_e, x_t)\n",
    "        # t_acc = selected_acc\n",
    "        # output = ''\n",
    "\n",
    "        # if l_loss is not None:\n",
    "        #     l_loss_window.append(l_loss)\n",
    "        # if s_loss is not None:\n",
    "        #     s_loss_window.append(s_loss)\n",
    "        acc_all.append(t_acc)\n",
    "        energy_all.append(selected_energy)\n",
    "\n",
    "        # smoothed_l_loss = moving_average(l_loss_window, window_size=1000)\n",
    "        # smoothed_s_loss = moving_average(s_loss_window, window_size=1000)\n",
    "        avg_acc = np.mean(acc_all)\n",
    "        avg_energy = np.mean(energy_all)\n",
    "\n",
    "        Q = max(0.0, Q + h_tilde - t_acc)\n",
    "        log(results, t, t_i, output, avg_acc, avg_energy, x_t) #, smoothed_l_loss, smoothed_s_loss)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71fb4f-e6c0-495f-bca0-4eaa1520d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(results, t, t_i, output, t_acc, t_energy, x_t): #, l_loss, s_loss):\n",
    "    results.append({\n",
    "        'iteration': t,\n",
    "        'input': t_i,\n",
    "        'best_output': output,\n",
    "        'chosen_models_avg_accuracy': t_acc,\n",
    "        'chosen_models_avg_energy': t_energy,\n",
    "        'chosen_model': x_t,\n",
    "        # 'l_loss': l_loss,\n",
    "        # 's_loss': s_loss\n",
    "    })\n",
    "    # log_data = {\n",
    "    #     'iteration': t,\n",
    "    #     'chosen_model_accuracy': t_acc\n",
    "    # }\n",
    "        \n",
    "    # if l_loss is not None: log_data['l_loss'] = l_loss\n",
    "    # if s_loss is not None: log_data['s_loss'] = s_loss\n",
    "        \n",
    "    # wandb.log(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f4257-4e9b-49ba-ad82-312b64d73ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bernoulli(p_t):\n",
    "    return random.random() < p_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab290fb6-de85-40ca-bc29-9bf3654a9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def querySelectedModel(t, t_e, x_t):\n",
    "    if x_t == \"large\":\n",
    "        output = df_combined_outputs[\"wmt14\"][t][\"13b\"]\n",
    "    else:\n",
    "        output =  df_combined_outputs[\"wmt14\"][t][\"tiny\"]\n",
    "        \n",
    "    return output, calculate_bleu(output, t_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f84c0-4552-4f62-bf95-19cddaed2bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def queryBest(t, t_i, t_e, l_predictor, s_predictor):\n",
    "#     l_acc, s_acc = predict(t_i, l_predictor, s_predictor)\n",
    "#     if l_acc > s_acc: # use larger model, e.g. 7b llama\n",
    "#         output = df_combined_outputs[\"wmt14\"][t][\"13b\"]\n",
    "#     else: # use smaller model for all other cases, e.g. 3b llama\n",
    "#         output =  df_combined_outputs[\"wmt14\"][t][\"tiny\"]\n",
    "\n",
    "#     return output, calculate_bleu(output, t_e)\n",
    "#     # return output, calculate_rouge(output, t_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ce7f4c-3666-4468-ad22-834e0530dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    data_list = list(data)  \n",
    "    if len(data_list) == 0:\n",
    "        return 0.0 \n",
    "    if len(data_list) < window_size:\n",
    "        return sum(data_list) / len(data_list)\n",
    "    return sum(data_list[-window_size:]) / window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d6079-a233-4862-8e7f-918c12cb4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_loss(predicted_accuracy, true_accuracy):\n",
    "    predicted_tensor = torch.tensor([predicted_accuracy], dtype=torch.float32)\n",
    "    true_tensor = torch.tensor([true_accuracy], dtype=torch.float32)\n",
    "\n",
    "    loss = F.mse_loss(predicted_tensor, true_tensor)\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16dc77-e1db-4a51-a8bc-c1f76e85c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgdStep(large_model_predictor, small_model_predictor, t_c):\n",
    "    predicted_large_label, predicted_small_label = 0, 0\n",
    "    if large_model_predictor and small_model_predictor != None: \n",
    "        predicted_large_label = large_model_predictor.predict(t_c['input_text'])[0][0].replace(\"__label__\", \"\")\n",
    "        predicted_small_label = small_model_predictor.predict(t_c['input_text'])[0][0].replace(\"__label__\", \"\")\n",
    "    \n",
    "    with open(\"fasttext_large.txt\", \"w\") as f:\n",
    "        f.write(f\"__label__{t_c['large_model_accuracy']} {t_c['input_text']}\\n\")\n",
    "    with open(\"fasttext_small.txt\", \"w\") as f:\n",
    "        f.write(f\"__label__{t_c['small_model_accuracy']} {t_c['input_text']}\\n\")\n",
    "\n",
    "    if os.path.exists(\"large_predictor.bin\"):\n",
    "        large_model_predictor = fastText.train_supervised(input=\"fasttext_large.txt\", epoch=1, lr=1.0, wordNgrams=2, inputModel=\"large_predictor.bin\")\n",
    "    else:\n",
    "        large_model_predictor = fastText.train_supervised(input=\"fasttext_large.txt\", epoch=1, lr=1.0, wordNgrams=2)\n",
    "\n",
    "    if os.path.exists(\"small_predictor.bin\"):\n",
    "        small_model_predictor = fastText.train_supervised(input=\"fasttext_small.txt\", epoch=1, lr=1.0, wordNgrams=2, inputModel=\"small_predictor.bin\")\n",
    "    else:\n",
    "        small_model_predictor = fastText.train_supervised(input=\"fasttext_small.txt\", epoch=1, lr=1.0, wordNgrams=2)\n",
    "\n",
    "    large_model_loss = compute_mse_loss(float(predicted_large_label), t_c['large_model_accuracy'])\n",
    "    small_model_loss = compute_mse_loss(float(predicted_small_label), t_c['small_model_accuracy'])\n",
    "\n",
    "    # print(f\"Large Stats(predicted, actual): {predicted_large_label}, {t_c['large_model_accuracy']}\")\n",
    "    # print(f\"Mean Square Error: {large_model_loss}\")\n",
    "    # print(f\"Small Stats(predicted, actual): {predicted_small_label}, {t_c['small_model_accuracy']}\")\n",
    "    # print(f\"Mean Square Error: {large_model_loss}\")\n",
    "\n",
    "    return large_model_predictor, small_model_predictor, large_model_loss, small_model_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0e73e-7a06-4071-9175-adbd53710be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(text, l_predictor, s_predictor):\n",
    "    l_predicted_label = l_predictor.predict(text)[0][0]\n",
    "    l_predicted_accuracy = int(round(float(l_predicted_label.replace('__label__', ''))))\n",
    "\n",
    "    s_predicted_label = s_predictor.predict(text)[0][0]\n",
    "    s_predicted_accuracy = int(round(float(s_predicted_label.replace('__label__', ''))))\n",
    "\n",
    "    return l_predicted_accuracy, s_predicted_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d56eb4-a502-4583-961d-7b7c39eccd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(t, t_i, t_e):\n",
    "    s_output = df_combined_outputs[\"wmt14\"][t][\"tiny\"]\n",
    "    l_output = df_combined_outputs[\"wmt14\"][t][\"13b\"]\n",
    "    \n",
    "    # WMT14\n",
    "    s_acc = calculate_bleu(s_output, t_e)\n",
    "    l_acc = calculate_bleu(l_output, t_e)\n",
    "\n",
    "    # CNN Dailymail\n",
    "    # s_acc = calculate_rouge(s_output, t_e)['rouge1']\n",
    "    # l_acc = calculate_rouge(l_output, t_e)['rouge1']\n",
    "\n",
    "    return {\n",
    "        'input_text': t_i,\n",
    "        'large_model_accuracy': l_acc,\n",
    "        'small_model_accuracy': s_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657f810-6521-4073-ab4d-bb1e7dee9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(l_predictor, s_predictor, t, p_t):\n",
    "    if p_t > 0.5:\n",
    "        if t % int(math.sqrt(t)) == 0:\n",
    "            print(\"Checkpoint\")\n",
    "            l_predictor, s_predictor = save_models(l_predictor, s_predictor)\n",
    "    else:\n",
    "        if t % max(1, int(1 / math.sqrt(t))) == 0:\n",
    "            print(\"Checkpoint\")\n",
    "            l_predictor, s_predictor = save_models(l_predictor, s_predictor)\n",
    "\n",
    "    return l_predictor, s_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534194e3-df63-47f4-8aac-382813becd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(l_predictor, s_predictor):\n",
    "    if l_predictor:\n",
    "        l_predictor.save_model(\"large_predictor.bin\")\n",
    "    if s_predictor:\n",
    "        s_predictor.save_model(\"small_predictor.bin\")\n",
    "\n",
    "    return l_predictor, s_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c404d0a7-f482-44d8-ac62-3d34c5b59f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_record(T, V, h_tilde, c):\n",
    "    # wandb.init(project=\"classifier\")\n",
    "    # stop_event = threading.Event()\n",
    "    # hw_monitor = HWMonitor(monitoring_freq=1.0, stop_event=threading.Event())\n",
    "    # hw_monitor.start()\n",
    "\n",
    "    \n",
    "    results = algorithm(T, V, h_tilde, c)\n",
    "\n",
    "    # stop_event.set() \n",
    "    # hw_monitor.join()\n",
    "    # wandb.finish()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d8728-11b0-470c-9da5-29e2262b5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_tilde_config = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58577c9-7a2c-4b37-9b8b-2b1c4233db6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = run_and_record(2999, 0.01, h_tilde_config, 5)\n",
    "with open('experiments/fasttext/wmt14_results_V0.01' + '_h' + str(h_tilde_config) + '.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e68a72-0389-43ee-a44f-ec2394df0add",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = run_and_record(2999, 0.1, h_tilde_config, 5)\n",
    "with open('experiments/fasttext/wmt14_results_V0.1' + '_h' + str(h_tilde_config) + '.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff8842-aa08-4d69-b2c7-11f8db448c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = run_and_record(2999, 1, h_tilde_config, 5)\n",
    "with open('experiments/fasttext/wmt14_results_V1' + '_h' + str(h_tilde_config) + '.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078f484-fe14-4775-8275-b504810a0f1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = run_and_record(2999, 10, h_tilde_config, 5)\n",
    "with open('experiments/fasttext/wmt14_results_V10' + '_h' + str(h_tilde_config) + '.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c2eb1-ddd1-4a93-8669-c0a12834919d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = run_and_record(2999, 100, h_tilde_config, 5)\n",
    "with open('experiments/fasttext/wmt14_results_V100' + '_h' + str(h_tilde_config) + '.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579438d-77e5-4db0-a69e-dc6c46536b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = run_and_record(2999, 1000, h_tilde_config, 5)\n",
    "with open('experiments/fasttext/wmt14_results_V1000' + '_h' + str(h_tilde_config) + '.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dedf1c-14c5-48d1-808b-ae3d40e5e991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = run_and_record(2999, 10000, h_tilde_config, 5)\n",
    "with open('experiments/fasttext/wmt14_results_V10000' + '_h' + str(h_tilde_config) + '.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11302c35-7f5d-44a0-b4ca-9c76c5427d75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = run_and_record(2999, 100000, h_tilde_config, 5)\n",
    "with open('experiments/fasttext/wmt14_results_V100000' + '_h' + str(h_tilde_config) + '.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24211535-1fae-4a68-b78b-1d84e6ceaa21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
